{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69cacbfb",
   "metadata": {},
   "source": [
    "# Create project data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847c2aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfr\\.conda\\envs\\dml\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# For dealing with files we use the built-in python module `Path`\n",
    "# It provides a nice abstraction of the file system, compared to working with strings only.\n",
    "# It also makes your code more portable, i.e. easier to share with someone using another operating system.\n",
    "from pathlib import Path\n",
    "# Some file system operation are not covered by 'Path' and we use 'shutil' for that\n",
    "import shutil\n",
    "\n",
    "# Regular expressions are used to find patterns in strings\n",
    "import re\n",
    "\n",
    "# For splitting the data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c79782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8091\n",
      "C:\\Users\\Wolfr\\deep-machine-learning\\project\\flickr8k\\Images\\1000268201_693b08cb0e.jpg\n"
     ]
    }
   ],
   "source": [
    "# Path to Flickr8K_ photos\n",
    "path_Flickr_jpg = \"./flickr8k/Images\"\n",
    "\n",
    "image_all = Path.cwd() / path_Flickr_jpg\n",
    "\n",
    "all_image_filenames = list(image_all.glob(\"*.jpg\"))\n",
    "\n",
    "print(len(all_image_filenames))\n",
    "print(all_image_filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04283ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset will be comprised of:\n",
      "Training:\t6472 \n",
      "Validation:\t1619\n"
     ]
    }
   ],
   "source": [
    "split_ratio_dataset = 0.2\n",
    "\n",
    "image_train, image_val = \\\n",
    "train_test_split(all_image_filenames,  \n",
    "              test_size = split_ratio_dataset,\n",
    "              random_state = 2)\n",
    "\n",
    "print(\"The dataset will be comprised of:\")\n",
    "print(f\"Training:\\t{len(image_train)} \\nValidation:\\t{len(image_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a220215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirectories = {\"./image_train\": image_train,\n",
    "                 \"./image_val\": image_val,\n",
    "                 }\n",
    "\n",
    "for subdirectory in subdirectories.keys():\n",
    "    subdirectory = Path(subdirectory)\n",
    "    subdirectory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "def fill_sub_dir(sub_dir, file_subset):\n",
    "    \"\"\"This function copies files from the `train_all` to a `<sub_dir>`\n",
    "    A more efficient solution would be to use \"symbolic links\" (see https://kb.iu.edu/d/abbe)\n",
    "    but for simplicity hard copies is used instead.\n",
    "    \"\"\"\n",
    "    for file in file_subset:\n",
    "        file_path = Path.cwd() / sub_dir / file.name\n",
    "        shutil.copyfile(file, file_path)\n",
    "\n",
    "for sub_dir, file_subset in subdirectories.items():\n",
    "    fill_sub_dir(sub_dir, file_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df62f0ef",
   "metadata": {},
   "source": [
    "Now, test whether the images are splited:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2b87881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6472\n",
      "1619\n"
     ]
    }
   ],
   "source": [
    "train_path = \"./image_train\"\n",
    "image_train = Path.cwd() / train_path\n",
    "image_filenames = list(image_train.glob(\"*.jpg\"))\n",
    "print(len(image_filenames))\n",
    "\n",
    "val_path = \"./image_val\"\n",
    "image_val = Path.cwd() / val_path\n",
    "image_filenames = list(image_val.glob(\"*.jpg\"))\n",
    "print(len(image_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5646a6e",
   "metadata": {},
   "source": [
    "Now split the txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5ddd95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000268201_693b08cb0e.jpg\n",
      "6472\n",
      "1003163366_44323f5815.jpg\n",
      "1619\n"
     ]
    }
   ],
   "source": [
    "# train_path = \"./image_train\"\n",
    "# image_train = Path.cwd() / train_path\n",
    "# val_path = \"./image_val\"\n",
    "# image_val = Path.cwd() / val_path\n",
    "\n",
    "# import os\n",
    "# list_train = os.listdir(image_train)\n",
    "# print(list_train[0])\n",
    "# print(len(list_train))\n",
    "# list_val = os.listdir(image_val)\n",
    "# print(list_val[0])\n",
    "# print(len(list_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73834318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to caption file\n",
    "# import pandas as pd\n",
    "# caption_file = './flickr8k/captions.txt'\n",
    "# dataset = pd.read_csv(caption_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
